{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "cnlp",
   "display_name": "ezra",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Transformer models\n",
    "\n",
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanziconv import HanziConv\n",
    "from data import read_bible\n",
    "\n",
    "unv = read_bible('data/dnstrunv.tgz')\n",
    "unv['text_s'] = unv.text.apply(HanziConv.toSimplified)"
   ]
  },
  {
   "source": [
    "## Compute embeddings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "max_seq = unv.text_s.str.len().max()\n",
    "searches = ['挂虑 祈祷', '喜乐 事奉', '求救', '信心 行事']\n",
    "\n",
    "def save_embeddings(searches_emb, verse_emb, path: str):\n",
    "    with open(path, \"wb\") as fOut:\n",
    "        pickle.dump({'searches_emb': searches_emb, 'verse_emb': verse_emb}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def compute_embeddings(model: str):\n",
    "    model = SentenceTransformer(model)\n",
    "    model.max_seq_length = max_seq\n",
    "    searches_emb = model.encode(searches)\n",
    "    verse_emb = model.encode(unv.text_s, show_progress_bar=True, num_workers=2)\n",
    "    save_embeddings(f'data/{model}-embeddings.pkl', searches_emb, verse_emb)\n",
    "    return searches_emb, verse_emb\n",
    "\n",
    "def search(searches_emb, verse_emb):\n",
    "    results = util.semantic_search(searches_emb, verse_emb)\n",
    "    for i, search_results in enumerate(results):\n",
    "        print(f'Searches for {searches[i]}:')\n",
    "        for top_k in search_results:\n",
    "            print(f'Score: {top_k[\"score\"]:7.4f} {unv.text.loc[top_k[\"corpus_id\"]]}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.012742  ,  0.07456179,  0.03821773, ...,  0.01008224,\n",
       "         0.10611277, -0.06496906],\n",
       "       [-0.00446616,  0.04929008,  0.00206162, ..., -0.02148391,\n",
       "        -0.01632529, -0.00246834],\n",
       "       [-0.01185791,  0.00333456, -0.04894161, ..., -0.00349449,\n",
       "        -0.01004079,  0.02232193],\n",
       "       ...,\n",
       "       [ 0.00756844, -0.0408489 , -0.01786444, ...,  0.02728658,\n",
       "         0.01209383, -0.02924234],\n",
       "       [ 0.08686031,  0.06604788, -0.0246829 , ...,  0.02659308,\n",
       "         0.01361549,  0.02791402],\n",
       "       [ 0.03772836, -0.01862286,  0.01920143, ...,  0.01515482,\n",
       "        -0.06437556,  0.02548239]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "du = compute_embeddings('distiluse-base-multilingual-cased-v2')\n",
    "du[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searches for 挂虑 祈祷:\nScore:  0.8784 不住地禱告，\nScore:  0.6724 請弟兄們為我們禱告。\nScore:  0.6638 你們要恆切禱告，在此警醒感恩。\nScore:  0.6236 求你從天上垂聽他們的禱告祈求，使他們得勝。\nScore:  0.6216 求你在天上垂聽他們的禱告祈求，使他們得勝。\nScore:  0.6107 神啊，求你聽我的禱告，留心聽我口中的言語。\nScore:  0.6091 你們禱告，無論求甚麼，只要信，就必得著。」\nScore:  0.6088 應當一無掛慮，只要凡事藉著禱告、祈求，和感謝，將你們所要的告訴神。\nScore:  0.5979 你們要呼求我，禱告我，我就應允你們。\nScore:  0.5791 聽禱告的主啊，凡有血氣的都要來就你。\n\nSearches for 喜乐 事奉:\nScore:  0.6796 要常常喜樂，\nScore:  0.4753 折腳折手的、\nScore:  0.4182 惟有義人必然歡喜，在神面前高興快樂。\nScore:  0.4167 猶大人有光榮，歡喜快樂而得尊貴。\nScore:  0.4079 說：\nScore:  0.4074 卑微的弟兄升高，就該喜樂；\nScore:  0.3984 以利戶又說：\nScore:  0.3984 以利戶又說：\nScore:  0.3937 你們要靠主常常喜樂。我再說，你們要喜樂。\nScore:  0.3900 不住地禱告，\n\nSearches for 求救:\nScore:  0.4954 說：\nScore:  0.4761 不住地禱告，\nScore:  0.4265 拯救我的主啊，求你快快幫助我！\nScore:  0.4238 亞希雅、哈難、亞難、\nScore:  0.4010 折腳折手的、\nScore:  0.3940 a\nScore:  0.3940 a\nScore:  0.3940 a\nScore:  0.3940 a\nScore:  0.3940 a\n\nSearches for 信心 行事:\nScore:  0.4612 可見，信心是與他的行為並行，而且信心因著行為才得成全。\nScore:  0.4397 必有人說：「你有信心，我有行為；你將你沒有行為的信心指給我看，我便藉著我的行為，將我的信心指給你看。」\nScore:  0.4238 你有信心，就當在神面前守著。人在自己以為可行的事上能不自責，就有福了。\nScore:  0.4053 使徒對主說：「求主加增我們的信心。」\nScore:  0.4017 並且仰望神的應許，總沒有因不信心裡起疑惑，反倒因信心裡得堅固，將榮耀歸給神，\nScore:  0.3920 凡事包容，凡事相信，凡事盼望，凡事忍耐。\nScore:  0.3805 且滿心相信神所應許的必能做成。\nScore:  0.3774 他所說的話，有信的，有不信的。\nScore:  0.3723 這話是可信的，是十分可佩服的。\nScore:  0.3664 並且得著你們信心的果效，就是靈魂的救恩。\n\n"
     ]
    }
   ],
   "source": [
    "search(*du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception when trying to download https://sbert.net/models/bert-base-chinese.zip. Response 404\n",
      "WARNING:root:SentenceTransformer-Model https://sbert.net/models/bert-base-chinese.zip not found. Try to create it from scratch\n",
      "WARNING:root:Try to create Transformer Model bert-base-chinese with mean pooling\n",
      "Downloading: 100%|██████████| 624/624 [00:00<00:00, 165kB/s]\n",
      "Downloading: 100%|██████████| 412M/412M [22:01<00:00, 312kB/s]\n",
      "Downloading: 100%|██████████| 110k/110k [00:01<00:00, 107kB/s]  \n",
      "Downloading: 100%|██████████| 269k/269k [00:01<00:00, 171kB/s]\n",
      "Batches: 100%|██████████| 972/972 [3:09:39<00:00, 11.71s/it]\n"
     ]
    }
   ],
   "source": [
    "cb = compute_embeddings('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searches for 挂虑 祈祷:\nScore:  0.7046 我便禁食，披麻蒙灰，定意向主神祈禱懇求。\nScore:  0.6962 我想念神，就煩躁不安；我沉吟悲傷，心便發昏。（細拉）\nScore:  0.6863 每逢為你們眾人祈求的時候，常是歡歡喜喜地祈求。\nScore:  0.6860 我勸你，第一要為萬人懇求、禱告、代求、祝謝；\nScore:  0.6840 從何羅念有喊荒涼大毀滅的哀聲：\nScore:  0.6720 「當記念安息日，守為聖日。\nScore:  0.6706 我有憂愁，願能自慰；我心在我裡面發昏。\nScore:  0.6700 恐懼戰兢歸到我身；驚恐漫過了我。\nScore:  0.6697 在思念夜中、異象之間，世人沉睡的時候，\nScore:  0.6662 有一宗人（宗：原文是代；下同），咒詛父親，不給母親祝福。\n\nSearches for 喜乐 事奉:\nScore:  0.8040 要常常喜樂，\nScore:  0.7612 常在殿裡稱頌神。\nScore:  0.7516 我靈以神我的救主為樂；\nScore:  0.7488 總要察驗何為主所喜悅的事。\nScore:  0.7441 卑微的弟兄升高，就該喜樂；\nScore:  0.7429 不住地禱告，\nScore:  0.7420 猶大人有光榮，歡喜快樂而得尊貴。\nScore:  0.7405 散布亮光是為義人；預備喜樂是為正直人。\nScore:  0.7403 所羅門因為求這事，就蒙主喜悅。\nScore:  0.7373 在那裡傳福音。\n\nSearches for 求救:\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\nScore:  0.7817 a\n\nSearches for 信心 行事:\nScore:  0.7413 但要凡事察驗；善美的要持守，\nScore:  0.7335 我知道世人，莫強如終身喜樂行善；\nScore:  0.7248 你所命定的法度是憑公義和至誠。\nScore:  0.7236 若是能行，總要盡力與眾人和睦。\nScore:  0.7229 在含地行奇事，在紅海行可畏的事。\nScore:  0.7157 凡你們所做的都要憑愛心而做。\nScore:  0.7154 「人若是公義，且行正直與合理的事：\nScore:  0.7113 要常常喜樂，\nScore:  0.7085 靠你有力量、心中想往錫安大道的，這人便為有福！\nScore:  0.7073 不要以惡報惡；眾人以為美的事要留心去做。\n\n"
     ]
    }
   ],
   "source": [
    "search(*cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 62%|██████▏   | 627M/1.01G [21:36<13:19, 484kB/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Ken/.cache/torch/sentence_transformers/sbert.net_models_stsb-xlm-r-multilingual'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/ezra37/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                             \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ezra37/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ezra37/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-2e31ad79e2b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stsb-xlm-r-multilingual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-00ce54856108>\u001b[0m in \u001b[0;36mcompute_embeddings\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msearches_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ezra37/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[1;32m     91\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ezra37/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ezra37/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Ken/.cache/torch/sentence_transformers/sbert.net_models_stsb-xlm-r-multilingual'"
     ]
    }
   ],
   "source": [
    "sts = compute_embeddings('stsb-xlm-r-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 501M/501M [17:07<00:00, 487kB/s]\n",
      "Batches: 100%|██████████| 972/972 [1:17:18<00:00,  4.77s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "[Errno 63] File name too long: 'data/SentenceTransformer(\\n  (0): Transformer(\\n    (auto_model): DistilBertModel(\\n      (embeddings): Embeddings(\\n        (word_embeddings): Embedding(119547, 768, padding_idx=0)\\n        (position_embeddings): Embedding(512, 768)\\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n        (dropout): Dropout(p=0.1, inplace=False)\\n      )\\n      (transformer): Transformer(\\n        (layer): ModuleList(\\n          (0): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (1): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (2): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (3): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (4): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (5): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (1): Pooling()\\n)-embeddings.pkl'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-59092aaa5d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quora-distilbert-multilingual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-783fda7b0d7f>\u001b[0m in \u001b[0;36mcompute_embeddings\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msearches_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mverse_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msave_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearches_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverse_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'data/{model}-embeddings.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msearches_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverse_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-783fda7b0d7f>\u001b[0m in \u001b[0;36msave_embeddings\u001b[0;34m(searches_emb, verse_emb, path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearches_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverse_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfOut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'searches_emb'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msearches_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verse_emb'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mverse_emb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfOut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 63] File name too long: 'data/SentenceTransformer(\\n  (0): Transformer(\\n    (auto_model): DistilBertModel(\\n      (embeddings): Embeddings(\\n        (word_embeddings): Embedding(119547, 768, padding_idx=0)\\n        (position_embeddings): Embedding(512, 768)\\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n        (dropout): Dropout(p=0.1, inplace=False)\\n      )\\n      (transformer): Transformer(\\n        (layer): ModuleList(\\n          (0): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (1): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (2): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (3): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (4): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n          (5): TransformerBlock(\\n            (attention): MultiHeadSelfAttention(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n            )\\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            (ffn): FFN(\\n              (dropout): Dropout(p=0.1, inplace=False)\\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            )\\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (1): Pooling()\\n)-embeddings.pkl'"
     ]
    }
   ],
   "source": [
    "db = compute_embeddings('quora-distilbert-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c79d3bf8d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "search(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm = compute_verse_embeddings('paraphrase-xlm-r-multilingual-v1')"
   ]
  }
 ]
}