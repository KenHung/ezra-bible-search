{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "cnlp",
   "display_name": "ezra",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Search within 10 verses\n",
    "\n",
    "Simple notebook POC for searching with in 10 Bible verses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vers = [\n",
    "    '我靠主大大地喜乐，因为你们思念我的心如今又发生；你们向来就思念我，只是没得机会。',\n",
    "    '应当一无挂虑，只要凡事借着祷告、祈求，和感谢，将你们所要的告诉　神。',\n",
    "    '我在急难中求告耶和华，向我的　神呼求。他从殿中听了我的声音；我在他面前的呼求入了他的耳中。',\n",
    "    '　神啊，我曾求告你，因为你必应允我；求你向我侧耳，听我的言语。',\n",
    "    '人的愚昧倾败他的道；他的心也抱怨耶和华。',\n",
    "    '耶稣对他说：「你若能信，在信的人，凡事都能。」',\n",
    "    '约书亚对以色列人说：「耶和华－你们列祖的　神所赐给你们的地，你们耽延不去得，要到几时呢？',\n",
    "    '所罗门说：「耶和华－以色列的　神是应当称颂的！因他亲口向我父大卫所应许的，也亲手成就了。',\n",
    "    '「因为你富有的时候，不欢心乐意地事奉耶和华－你的　神，',\n",
    "    '你们当乐意事奉耶和华，当来向他歌唱！'\n",
    "]\n",
    "searches = ['挂虑 祈祷', '喜乐 事奉', '求救', '信心 行事']"
   ]
  },
  {
   "source": [
    "## Tokenize w/o Stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Paddle enabled successfully......\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.enable_paddle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[pair('我', 'r'), pair('靠', 'p'), pair('主大大地喜乐，', 'nt'), pair('因为', 'p'), pair('你们', 'r'), pair('思念', 'v'), pair('我', 'r'), pair('的', 'u'), pair('心', 'n'), pair('如今', 't'), pair('又', 'd'), pair('发生', 'v'), pair('；', 'v'), pair('你们', 'r'), pair('向来', 'd'), pair('就', 'd'), pair('思念', 'v'), pair('我', 'r'), pair('，', 'v'), pair('只是', 'd'), pair('没得', 'v'), pair('机会', 'n'), pair('。', 'v')]\n[pair('应当', 'v'), pair('一无', 'v'), pair('挂虑', 'vn'), pair('，', 'n'), pair('只要', 'c'), pair('凡事', 'n'), pair('借', 'v'), pair('着', 'u'), pair('祷告', 'v'), pair('、', 'n'), pair('祈求', 'v'), pair('，', 'n'), pair('和', 'c'), pair('感谢', 'v'), pair('，', 'n'), pair('将', 'p'), pair('你们', 'r'), pair('所', 'u'), pair('要', 'v'), pair('的', 'u'), pair('告诉', 'v'), pair('\\u3000神。', 'nr')]\n[pair('我', 'r'), pair('在', 'p'), pair('急难', 'a'), pair('中', 'f'), pair('求告', 'v'), pair('耶和华，', 'PER'), pair('向', 'p'), pair('我', 'r'), pair('的', 'u'), pair('\\u3000神', 'n'), pair('呼', 'v'), pair('求', 'v'), pair('。', 'v'), pair('他', 'r'), pair('从', 'p'), pair('殿', 'n'), pair('中', 'f'), pair('听', 'v'), pair('了', 'u'), pair('我', 'r'), pair('的', 'u'), pair('声音', 'n'), pair('；', 'v'), pair('我', 'r'), pair('在', 'p'), pair('他', 'r'), pair('面前', 'f'), pair('的', 'u'), pair('呼求', 'vn'), pair('入', 'v'), pair('了', 'u'), pair('他', 'r'), pair('的', 'u'), pair('耳', 'n'), pair('中', 'f'), pair('。', 'v')]\n[pair('神', 'n'), pair('啊', 'xc'), pair('，', 'v'), pair('我', 'r'), pair('曾', 'd'), pair('求', 'v'), pair('告', 'v'), pair('你', 'r'), pair('，', 'v'), pair('因为', 'p'), pair('你', 'r'), pair('必', 'd'), pair('应允', 'v'), pair('我', 'r'), pair('；求', 'v'), pair('你', 'r'), pair('向', 'p'), pair('我', 'r'), pair('侧耳', 'n'), pair('，', 'v'), pair('听', 'v'), pair('我', 'r'), pair('的', 'u'), pair('言语', 'n'), pair('。', 'v')]\n[pair('人', 'n'), pair('的', 'u'), pair('愚昧', 'an'), pair('倾败', 'v'), pair('他', 'r'), pair('的', 'u'), pair('道', 'n'), pair('；', 'v'), pair('他', 'r'), pair('的', 'u'), pair('心', 'n'), pair('也', 'd'), pair('抱怨', 'v'), pair('耶和华。', 'nz')]\n[pair('耶稣', 'PER'), pair('对', 'p'), pair('他', 'r'), pair('说', 'v'), pair('：「', 'nr'), pair('你', 'r'), pair('若', 'c'), pair('能', 'v'), pair('信，', 'v'), pair('在', 'p'), pair('信', 'n'), pair('的', 'u'), pair('人', 'n'), pair('，', 'v'), pair('凡事', 'n'), pair('都', 'd'), pair('能', 'v'), pair('。」', 'v')]\n[pair('约书亚', 'PER'), pair('对', 'p'), pair('以色列', 'LOC'), pair('人', 'n'), pair('说', 'v'), pair('：「耶', 'nr'), pair('和', 'c'), pair('华－', 'nr'), pair('你们', 'r'), pair('列祖', 'v'), pair('的', 'u'), pair('\\u3000神', 'n'), pair('所', 'u'), pair('赐', 'v'), pair('给', 'p'), pair('你们', 'r'), pair('的', 'u'), pair('地', 'u'), pair('，', 'v'), pair('你们', 'r'), pair('耽延', 'v'), pair('不', 'd'), pair('去得', 'v'), pair('，', 'n'), pair('要', 'v'), pair('到', 'v'), pair('几', 'm'), pair('时', 'n'), pair('呢', 'xc'), pair('？', 'n')]\n[pair('所罗门', 'PER'), pair('说', 'v'), pair('：「耶', 'nr'), pair('和', 'c'), pair('华－', 'nz'), pair('以色列', 'LOC'), pair('的', 'u'), pair('\\u3000神', 'n'), pair('是', 'v'), pair('应当', 'v'), pair('称颂', 'v'), pair('的', 'u'), pair('！', 'n'), pair('因', 'p'), pair('他', 'r'), pair('亲口', 'd'), pair('向', 'p'), pair('我', 'r'), pair('父', 'n'), pair('大卫', 'PER'), pair('所', 'u'), pair('应', 'v'), pair('许', 'v'), pair('的', 'u'), pair('，', 'n'), pair('也', 'd'), pair('亲手', 'd'), pair('成就', 'v'), pair('了', 'u'), pair('。', 'n')]\n[pair('「', 'n'), pair('因为', 'p'), pair('你', 'r'), pair('富有', 'v'), pair('的', 'u'), pair('时候', 'n'), pair('，不欢心乐意', 'v'), pair('地', 'u'), pair('事', 'n'), pair('奉', 'v'), pair('耶', 'xc'), pair('和', 'c'), pair('华－', 'nr'), pair('你', 'r'), pair('的', 'u'), pair('\\u3000神，', 'nr')]\n[pair('你们', 'r'), pair('当', 'p'), pair('乐意', 'n'), pair('事', 'n'), pair('奉', 'v'), pair('耶和华，', 'PER'), pair('当来', 't'), pair('向', 'p'), pair('他', 'r'), pair('歌唱', 'v'), pair('！', 'n')]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(map(lambda v: pseg.lcut(v, use_paddle=True), vers))\n",
    "for tk in tokens:\n",
    "    print(tk)"
   ]
  },
  {
   "source": [
    "## Stem / Lemmatize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n[nltk_data]     nor servname provided, or not known>\n[nltk_data] Error loading omw: <urlopen error [Errno 8] nodename nor\n[nltk_data]     servname provided, or not known>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw')"
   ]
  },
  {
   "source": [
    "### Lemmatize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['感谢', '谢意', '谢谢', '道谢']\n['感激', '感谢']\n"
     ]
    }
   ],
   "source": [
    "syns = wn.synsets('感谢', pos='v', lang='cmn')\n",
    "for syn in syns:\n",
    "    print(syn.lemma_names(lang='cmn'))"
   ]
  },
  {
   "source": [
    "### Similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def similarity(token_a, token_b) -> float:\n",
    "    word_a, pos_a = token_a\n",
    "    if type(token_b) is str:\n",
    "        word_b = token_b\n",
    "        pos_b = None\n",
    "    else:\n",
    "        word_b, pos_b = token_b\n",
    "    if word_a == word_b:\n",
    "        return 1\n",
    "\n",
    "    if pos_a:\n",
    "        pos_a = map_pos(pos_a)\n",
    "    if pos_b:\n",
    "        pos_b = map_pos(pos_b)\n",
    "\n",
    "    asyns = wn.synsets(word_a, pos=pos_a, lang='cmn')\n",
    "    bsyns = wn.synsets(word_b, pos=pos_b, lang='cmn')\n",
    "    if asyns and bsyns:\n",
    "        sims = map(lambda p: wn.path_similarity(*p), itertools.product(asyns, bsyns))\n",
    "    elif asyns:\n",
    "        lemmas = (syn.lemma_names(lang='cmn') for syn in asyns)\n",
    "        sims = [(1 if word_b == lemma else 0) for lemma in lemmas]\n",
    "    elif bsyns:\n",
    "        lemmas = (syn.lemma_names(lang='cmn') for syn in bsyns)\n",
    "        sims = [(1 if word_a == lemma else 0) for lemma in lemmas]\n",
    "    else:\n",
    "        sims = [0]\n",
    "    return max(sims)\n",
    "\n",
    "def map_pos(pos: str) -> str:\n",
    "    wn_pos = {\n",
    "        'n': wn.NOUN,\n",
    "        'v': wn.VERB,\n",
    "        'a': wn.ADJ,\n",
    "        'd': wn.ADV\n",
    "    }\n",
    "    return wn_pos.get(pos[0]) or pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.1, 1.0, 1.0, 0, 1, 0.07142857142857142]\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    similarity(('感谢', 'v'), '感动'),\n",
    "    similarity(('感谢', 'v'), '谢意'),\n",
    "    similarity(('感谢', 'v'), '谢谢'),\n",
    "    similarity(('挂虑', 'v'), '挂念'),\n",
    "    similarity(('挂虑', 'v'), '挂虑'),\n",
    "    similarity(('祷告', 'v'), '祈求')\n",
    "]\n",
    "print(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[pair('我', 'r'), pair('靠', 'p'), pair('主大大地喜乐，', 'nt'), pair('因为', 'p'), pair('你们', 'r'), pair('思念', 'v'), pair('我', 'r'), pair('的', 'u'), pair('心', 'n'), pair('如今', 't'), pair('又', 'd'), pair('发生', 'v'), pair('；', 'v'), pair('你们', 'r'), pair('向来', 'd'), pair('就', 'd'), pair('思念', 'v'), pair('我', 'r'), pair('，', 'v'), pair('只是', 'd'), pair('没得', 'v'), pair('机会', 'n'), pair('。', 'v')]\n[('我', 'r'), ('靠', 'p'), ('主大大地喜乐，', 'nt'), ('因为', 'p'), ('你们', 'r'), ('思念', 'v'), ('我', 'r'), ('的', 'u'), ('心', 'n'), ('如今', 't'), ('又', 'd'), ('发生', 'v'), ('你们', 'r'), ('向来', 'd'), ('就', 'd'), ('思念', 'v'), ('我', 'r'), ('只是', 'd'), ('没得', 'v'), ('机会', 'n')]\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return [(word, pos) for word, pos in tokens if pos != 'x' and word not in '。，；⋯⋯、']\n",
    "\n",
    "print(tokens[0])\n",
    "print(remove_stopwords(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.07142857142857142\n1.0\n"
     ]
    }
   ],
   "source": [
    "def sentence_similarity(keywords, sentence):\n",
    "    keywords = remove_stopwords(keywords)\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    keywords_similarity = (max(similarity(kw, token) for token in sentence) for kw in keywords)\n",
    "    return sum(keywords_similarity) / len(keywords)\n",
    "\n",
    "search_tk = pseg.lcut(searches[0])\n",
    "print(sentence_similarity(search_tk, tokens[0]))\n",
    "print(sentence_similarity(search_tk, tokens[1]))"
   ]
  },
  {
   "source": [
    "## Jaccard Similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://bommaritollc.com/2014/06/12/fuzzy-match-sentences-python/\n",
    "# https://github.com/fxsjy/jieba"
   ]
  }
 ]
}